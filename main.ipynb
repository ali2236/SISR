{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "319fd90e",
   "metadata": {},
   "source": [
    "# Single Image Super Resolution\n",
    "Based on ESRGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2864f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "exc_env = 'local'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hr_shape = (2040, 2040)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f76918a",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Dataset\n",
    "1. download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a7f2f0-2012-45ee-8527-f43deb0cd081",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exc_env != 'local':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fbd4d4",
   "metadata": {},
   "source": [
    "2. unzip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "913e5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exc_env != 'local':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b035ae47",
   "metadata": {},
   "source": [
    "3. Create dataset access object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1304222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def denormalize(tensors):\n",
    "    \"\"\" Denormalizes image tensors using mean and std \"\"\"\n",
    "    for c in range(3):\n",
    "        tensors[:, c].mul_(std[c]).add_(mean[c])\n",
    "    return torch.clamp(tensors, 0, 255)\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, hr_shape):\n",
    "        hr_height, hr_width = hr_shape\n",
    "        # Transforms for low resolution images and high resolution images\n",
    "        self.lr_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((hr_height // 4, hr_height // 4), Image.BICUBIC),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        )\n",
    "        self.hr_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((hr_height, hr_height), Image.BICUBIC),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.files = sorted(glob.glob(root + \"/*.*\"))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "        img_lr = self.lr_transform(img)\n",
    "        img_hr = self.hr_transform(img)\n",
    "\n",
    "        return {\"lr\": img_lr, \"hr\": img_hr}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe65f33",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Architectural Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d16c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg19\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        vgg19_model = vgg19(pretrained=True)\n",
    "        self.vgg19_54 = nn.Sequential(*list(vgg19_model.features.children())[:35])\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.vgg19_54(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68739699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    The core module of paper: (Residual Dense Network for Image Super-Resolution, CVPR 18)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filters, res_scale=0.2):\n",
    "        super(DenseResidualBlock, self).__init__()\n",
    "        self.res_scale = res_scale\n",
    "\n",
    "        def block(in_features, non_linearity=True):\n",
    "            layers = [nn.Conv2d(in_features, filters, 3, 1, 1, bias=True)]\n",
    "            if non_linearity:\n",
    "                layers += [nn.LeakyReLU()]\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.b1 = block(in_features=1 * filters)\n",
    "        self.b2 = block(in_features=2 * filters)\n",
    "        self.b3 = block(in_features=3 * filters)\n",
    "        self.b4 = block(in_features=4 * filters)\n",
    "        self.b5 = block(in_features=5 * filters, non_linearity=False)\n",
    "        self.blocks = [self.b1, self.b2, self.b3, self.b4, self.b5]\n",
    "\n",
    "    def forward(self, x):\n",
    "        inputs = x\n",
    "        for block in self.blocks:\n",
    "            out = block(inputs)\n",
    "            inputs = torch.cat([inputs, out], 1)\n",
    "        return out.mul(self.res_scale) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc7fc288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualInResidualDenseBlock(nn.Module):\n",
    "    def __init__(self, filters, res_scale=0.2):\n",
    "        super(ResidualInResidualDenseBlock, self).__init__()\n",
    "        self.res_scale = res_scale\n",
    "        self.dense_blocks = nn.Sequential(\n",
    "            DenseResidualBlock(filters), DenseResidualBlock(filters), DenseResidualBlock(filters)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense_blocks(x).mul(self.res_scale) + x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa4fe1",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78a053",
   "metadata": {},
   "source": [
    "1. Generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a767a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorRRDB(nn.Module):\n",
    "    def __init__(self, channels, filters=64, num_res_blocks=16, num_upsample=2):\n",
    "        super(GeneratorRRDB, self).__init__()\n",
    "\n",
    "        # First layer\n",
    "        self.conv1 = nn.Conv2d(channels, filters, kernel_size=3, stride=1, padding=1)\n",
    "        # Residual blocks\n",
    "        self.res_blocks = nn.Sequential(*[ResidualInResidualDenseBlock(filters) for _ in range(num_res_blocks)])\n",
    "        # Second conv layer post residual blocks\n",
    "        self.conv2 = nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1)\n",
    "        # Upsampling layers\n",
    "        upsample_layers = []\n",
    "        for _ in range(num_upsample):\n",
    "            upsample_layers += [\n",
    "                nn.Conv2d(filters, filters * 4, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.PixelShuffle(upscale_factor=2),\n",
    "            ]\n",
    "        self.upsampling = nn.Sequential(*upsample_layers)\n",
    "        # Final output block\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(filters, channels, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.conv1(x)\n",
    "        out = self.res_blocks(out1)\n",
    "        out2 = self.conv2(out)\n",
    "        out = torch.add(out1, out2)\n",
    "        out = self.upsampling(out)\n",
    "        out = self.conv3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65cb100",
   "metadata": {},
   "source": [
    "2. Discriminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26ba9050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        in_channels, in_height, in_width = self.input_shape\n",
    "        patch_h, patch_w = int(in_height / 2 ** 4), int(in_width / 2 ** 4)\n",
    "        self.output_shape = (1, patch_h, patch_w)\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, first_block=False):\n",
    "            layers = []\n",
    "            layers.append(nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=1, padding=1))\n",
    "            if not first_block:\n",
    "                layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            layers.append(nn.Conv2d(out_filters, out_filters, kernel_size=3, stride=2, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        layers = []\n",
    "        in_filters = in_channels\n",
    "        for i, out_filters in enumerate([64, 128, 256, 512]):\n",
    "            layers.extend(discriminator_block(in_filters, out_filters, first_block=(i == 0)))\n",
    "            in_filters = out_filters\n",
    "\n",
    "        layers.append(nn.Conv2d(out_filters, 1, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ef56a",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60aa3e06",
   "metadata": {},
   "source": [
    "1. Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c904f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to C:\\Users\\Aligator/.cache\\torch\\hub\\checkpoints\\vgg19-dcbb9e9d.pth\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:1342\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1342\u001b[0m     h\u001b[39m.\u001b[39;49mrequest(req\u001b[39m.\u001b[39;49mget_method(), req\u001b[39m.\u001b[39;49mselector, req\u001b[39m.\u001b[39;49mdata, headers,\n\u001b[0;32m   1343\u001b[0m               encode_chunked\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mhas_header(\u001b[39m'\u001b[39;49m\u001b[39mTransfer-encoding\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m   1344\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py:1255\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1255\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py:1301\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1300\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1301\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py:1250\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1250\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py:1010\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1010\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[0;32m   1012\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1013\u001b[0m \n\u001b[0;32m   1014\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py:950\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[1;32m--> 950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py:1424\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1422\u001b[0m     server_hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[1;32m-> 1424\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context\u001b[39m.\u001b[39;49mwrap_socket(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock,\n\u001b[0;32m   1425\u001b[0m                                       server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[0;32m    501\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    502\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[0;32m    503\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[0;32m    504\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[0;32m    505\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    506\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    507\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[0;32m    508\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1040\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1041\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1308\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1309\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1310\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m generator \u001b[39m=\u001b[39m GeneratorRRDB(\u001b[39m3\u001b[39m, filters\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, num_res_blocks\u001b[39m=\u001b[39m\u001b[39m23\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m discriminator \u001b[39m=\u001b[39m Discriminator(input_shape\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m, \u001b[39m*\u001b[39mhr_shape))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 13\u001b[0m feature_extractor \u001b[39m=\u001b[39m FeatureExtractor()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m \u001b[39m# Set feature extractor to inference mode\u001b[39;00m\n\u001b[0;32m     16\u001b[0m feature_extractor\u001b[39m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m, in \u001b[0;36mFeatureExtractor.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[39msuper\u001b[39m(FeatureExtractor, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m----> 6\u001b[0m     vgg19_model \u001b[39m=\u001b[39m vgg19(pretrained\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvgg19_54 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(vgg19_model\u001b[39m.\u001b[39mfeatures\u001b[39m.\u001b[39mchildren())[:\u001b[39m35\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:142\u001b[0m, in \u001b[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    136\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing \u001b[39m\u001b[39m{\u001b[39;00msequence_to_str(\u001b[39mtuple\u001b[39m(keyword_only_kwargs\u001b[39m.\u001b[39mkeys()), separate_last\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mand \u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m as positional \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m     )\n\u001b[0;32m    140\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate(keyword_only_kwargs)\n\u001b[1;32m--> 142\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:228\u001b[0m, in \u001b[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[39mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[0;32m    226\u001b[0m     kwargs[weights_param] \u001b[39m=\u001b[39m default_weights_arg\n\u001b[1;32m--> 228\u001b[0m \u001b[39mreturn\u001b[39;00m builder(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\vgg.py:467\u001b[0m, in \u001b[0;36mvgg19\u001b[1;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39m\"\"\"VGG-19 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \n\u001b[0;32m    449\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39m    :members:\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m weights \u001b[39m=\u001b[39m VGG19_Weights\u001b[39m.\u001b[39mverify(weights)\n\u001b[1;32m--> 467\u001b[0m \u001b[39mreturn\u001b[39;00m _vgg(\u001b[39m\"\u001b[39m\u001b[39mE\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m, weights, progress, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\vgg.py:105\u001b[0m, in \u001b[0;36m_vgg\u001b[1;34m(cfg, batch_norm, weights, progress, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m model \u001b[39m=\u001b[39m VGG(make_layers(cfgs[cfg], batch_norm\u001b[39m=\u001b[39mbatch_norm), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(weights\u001b[39m.\u001b[39;49mget_state_dict(progress\u001b[39m=\u001b[39;49mprogress))\n\u001b[0;32m    106\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_api.py:66\u001b[0m, in \u001b[0;36mWeightsEnum.get_state_dict\u001b[1;34m(self, progress)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_dict\u001b[39m(\u001b[39mself\u001b[39m, progress: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Mapping[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m load_state_dict_from_url(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl, progress\u001b[39m=\u001b[39;49mprogress)\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\hub.py:731\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[1;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[0;32m    729\u001b[0m         r \u001b[39m=\u001b[39m HASH_REGEX\u001b[39m.\u001b[39msearch(filename)  \u001b[39m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[0;32m    730\u001b[0m         hash_prefix \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m r \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 731\u001b[0m     download_url_to_file(url, cached_file, hash_prefix, progress\u001b[39m=\u001b[39;49mprogress)\n\u001b[0;32m    733\u001b[0m \u001b[39mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[0;32m    734\u001b[0m     \u001b[39mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location)\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\hub.py:597\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[1;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[0;32m    595\u001b[0m file_size \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    596\u001b[0m req \u001b[39m=\u001b[39m Request(url, headers\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtorch.hub\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m--> 597\u001b[0m u \u001b[39m=\u001b[39m urlopen(req)\n\u001b[0;32m    598\u001b[0m meta \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39minfo()\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(meta, \u001b[39m'\u001b[39m\u001b[39mgetheaders\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[0;32m    516\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[1;32m--> 517\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[0;32m    519\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[0;32m    520\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m    533\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[1;32m--> 534\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[0;32m    535\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[0;32m    536\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[0;32m    537\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    495\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:1385\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[1;32m-> 1385\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[0;32m   1386\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[1;32mc:\\Users\\Aligator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\urllib\\request.py:1345\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1342\u001b[0m         h\u001b[39m.\u001b[39mrequest(req\u001b[39m.\u001b[39mget_method(), req\u001b[39m.\u001b[39mselector, req\u001b[39m.\u001b[39mdata, headers,\n\u001b[0;32m   1343\u001b[0m                   encode_chunked\u001b[39m=\u001b[39mreq\u001b[39m.\u001b[39mhas_header(\u001b[39m'\u001b[39m\u001b[39mTransfer-encoding\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m   1344\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1345\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1346\u001b[0m     r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m   1347\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "epochs = 5\n",
    "epoch = 0\n",
    "checkpoint_interval = 1\n",
    "sample_interval = 1\n",
    "learning_rate = 0.0002\n",
    "dataset_name = 'testing'\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = GeneratorRRDB(3, filters=64, num_res_blocks=23).to(device)\n",
    "discriminator = Discriminator(input_shape=(3, *hr_shape)).to(device)\n",
    "feature_extractor = FeatureExtractor().to(device)\n",
    "\n",
    "# Set feature extractor to inference mode\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Losses\n",
    "criterion_GAN = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "criterion_content = torch.nn.L1Loss().to(device)\n",
    "criterion_pixel = torch.nn.L1Loss().to(device)\n",
    "\n",
    "if epoch != 0:\n",
    "    # Load pretrained models\n",
    "    generator.load_state_dict(torch.load(f\"Models/generator_{epoch}.pth\"))\n",
    "    discriminator.load_state_dict(torch.load(\"Models/discriminator_{epoch}.pth\"))\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ImageDataset(f\"Dataset\\{dataset_name}\", hr_shape=hr_shape),\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "999a5ab9",
   "metadata": {},
   "source": [
    "2. Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f352e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m \u001b[39mimport\u001b[39;00m Variable\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m save_image\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch, epochs):\n\u001b[0;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m i, imgs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m      7\u001b[0m         batches_done \u001b[39m=\u001b[39m epoch \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(dataloader) \u001b[39m+\u001b[39m i\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "for epoch in range(epoch, epochs):\n",
    "    for i, imgs in enumerate(dataloader):\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "\n",
    "        # Configure model input\n",
    "        imgs_lr = Variable(imgs[\"lr\"].type(Tensor))\n",
    "        imgs_hr = Variable(imgs[\"hr\"].type(Tensor))\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((imgs_lr.size(0), *discriminator.output_shape))), requires_grad=False)\n",
    "\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate a high resolution image from low resolution input\n",
    "        gen_hr = generator(imgs_lr)\n",
    "\n",
    "        # Measure pixel-wise loss against ground truth\n",
    "        loss_pixel = criterion_pixel(gen_hr, imgs_hr)\n",
    "\n",
    "        warmup_batches = len(dataloader) * 1\n",
    "        if batches_done < warmup_batches:\n",
    "            # Warm-up (pixel-wise loss only)\n",
    "            loss_pixel.backward()\n",
    "            optimizer_G.step()\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [G pixel: %f]\"\n",
    "                % (epoch, epochs, i, len(dataloader), loss_pixel.item())\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Extract validity predictions from discriminator\n",
    "        pred_real = discriminator(imgs_hr).detach()\n",
    "        pred_fake = discriminator(gen_hr)\n",
    "\n",
    "        # Adversarial loss (relativistic average GAN)\n",
    "        loss_GAN = criterion_GAN(pred_fake - pred_real.mean(0, keepdim=True), valid)\n",
    "\n",
    "        # Content loss\n",
    "        gen_features = feature_extractor(gen_hr)\n",
    "        real_features = feature_extractor(imgs_hr).detach()\n",
    "        loss_content = criterion_content(gen_features, real_features)\n",
    "\n",
    "        # Total generator loss\n",
    "        loss_G = loss_content + 5e-3 * loss_GAN + 1e-2 * loss_pixel\n",
    "\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        pred_real = discriminator(imgs_hr)\n",
    "        pred_fake = discriminator(gen_hr.detach())\n",
    "\n",
    "        # Adversarial loss for real and fake images (relativistic average GAN)\n",
    "        loss_real = criterion_GAN(pred_real - pred_fake.mean(0, keepdim=True), valid)\n",
    "        loss_fake = criterion_GAN(pred_fake - pred_real.mean(0, keepdim=True), fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D = (loss_real + loss_fake) / 2\n",
    "\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, content: %f, adv: %f, pixel: %f]\"\n",
    "            % (\n",
    "                epoch,\n",
    "                epochs,\n",
    "                i,\n",
    "                len(dataloader),\n",
    "                loss_D.item(),\n",
    "                loss_G.item(),\n",
    "                loss_content.item(),\n",
    "                loss_GAN.item(),\n",
    "                loss_pixel.item(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if batches_done % sample_interval == 0:\n",
    "            # Save image grid with upsampled inputs and ESRGAN outputs\n",
    "            imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)\n",
    "            img_grid = denormalize(torch.cat((imgs_lr, gen_hr), -1))\n",
    "            save_image(img_grid, \"Training/%d.png\" % batches_done, nrow=1, normalize=False)\n",
    "\n",
    "        if batches_done % checkpoint_interval == 0:\n",
    "            # Save model checkpoints\n",
    "            torch.save(generator.state_dict(), \"Models/generator_%d.pth\" % epoch)\n",
    "            torch.save(discriminator.state_dict(), \"Models/discriminator_%d.pth\" %epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add0150",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_path = ''\n",
    "\n",
    "os.makedirs(\"Output\", exist_ok=True)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "\n",
    "# Prepare input\n",
    "image_tensor = Variable(transform(Image.open(image_path))).to(device).unsqueeze(0)\n",
    "\n",
    "# Upsample image\n",
    "with torch.no_grad():\n",
    "    sr_image = denormalize(generator(image_tensor)).cpu()\n",
    "\n",
    "# Save image\n",
    "fn = image_path.split(\"/\")[-1]\n",
    "save_image(sr_image, f\"Output/sr-{fn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4ea2e4b26b0fd95219da9fe00dd3bb328c5d875c7deaef4b029faf977d454da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
